# -*- eval: (setq org-media-note-screenshot-image-dir (concat default-directory "./static/Python 3 编码原理/")); -*-
:PROPERTIES:
:ID:       1BF5DBE4-65B6-40D8-BD3C-B41CD21A863C
:END:
#+LATEX_CLASS: my-article
#+DATE: <2021-07-27 Tue 15:38>
#+TITLE: Python 3 编码原理

* 一

#+BEGIN_SRC python
import sys, locale

s = "小甲"
print(s)
print(type(s))
print(sys.getdefaultencoding())
print(locale.getdefaultlocale())

with open("utf1","w",encoding = "utf-8") as f:
    f.write(s)
with open("gbk1","w",encoding = "gbk") as f:
    f.write(s)
with open("jis1","w",encoding = "shift-jis") as f:
    f.write(s)
#+END_SRC

* 一运行结果

#+BEGIN_SRC dart
小甲
<class 'str'>
utf-8
('en_US', 'UTF-8')
#+END_SRC

正如大家所想， 就是将“小甲”原样打印出来, 再把“小甲”存到 3 个文件中。（shift-jis 是日文编码格式）

这里解释一下打印出来的两个“utf-8”是什么意思：

上面的 utf-8 指：系统默认编码，不要把系统以为是操作系统，这里可以理解成 python3 的编译器本身。

下面的 utf-8 指：本地默认编码，这个才是操作系统的编码。（在 Windows 运行会变成 gbk）

现在我们分别查看 utf1 、gbk1、jis1 这三个文件的内容：

#+BEGIN_SRC awk
utf1 : 小甲
gbk1 : С▒▒▒
jis1 : ▒▒▒b
#+END_SRC

问题：
为什么 utf1 的内容很清楚，没有编码问题，而 gbk1 、jis1 的内容都出现了乱码？

解释：
因为我文件存储时用的编码格式不是 utf-8，而此时读取这两个文件时，使用的是 linux 操作系统的默认 编码“utf-8”。
那么写入磁盘时不是用 utf-8， 读出时却用 utf-8，当然读不出来了。（这里需要大家了解 encoding 的真实作用）

* 二

#+BEGIN_SRC python
#coding=gbk
import sys, locale

s = "小甲"
print(s)
print(type(s))
print(sys.getdefaultencoding())
print(locale.getdefaultlocale())

with open("utf2","w", encoding = "utf-8") as f:
    f.write(s)
with open("gbk2","w", encoding = "gbk") as f:
    f.write(s)
with open("jis2","w", encoding = "shift-jis") as f:
    f.write(s)
#+END_SRC

代码结结构一样很简单，但是请大家注意： 我在头部加了某个编码声明， 在代码运行前， 请大家自行猜测结果。

* 二运行结果

#+BEGIN_SRC python
灏忕敳
<class 'str'>
utf-8
('en_US', 'UTF-8')
Traceback (most recent call last):
  File "2", line 15, in <module>
    f.write(s)
UnicodeEncodeError: 'shift_jis' codec can't encode character '\u704f' in position 0: illegal multibyte sequence
#+END_SRC

问题来了：
- 代码中明明 ~s = “小甲”~ ， 为什么变成了 “灏忕敳” ？？
- 为什么 jis 的编码失败了？（之前顶多只出现了乱码的问题，还不会报错，那它内部到底发生了什 么？）
- “coding=gbk” 到底是什么意思？
- 我明明写了 “coding=gbk” 的编码声明，为什么系统编码、本地默认编码还是没有改变？（那我写了 有啥用？）

解释一下：以上这么多问题， 主要是因为没搞清楚头文件的 “coding=gbk” 编码声明是什么意思。
- 它的意思是 python3 编译器在读取该 =.py= 文件时候，我应该用什么格式将它 “解码”？只和读取有关，
所以当你确定你代码编辑时候用的是什么格式编码的，你才能把相应的编码格式写入头文件。
在此示范代码中，我用的是 linux 的默认编码编辑，也就是 utf-8，那么在后面运行的时候，却要求解释器用 =gbk= 去解码，自然很过分，就会出现了 s=“小甲” 乱码的问题。
大家一定要知道，编码是 “编” 和 “解” 的两个步骤，一定要一一对应才能正确解码。虽然通常我们 都叫“编码格式”，这是有一定误导性的。
实际上另一半是“解码格式”，要有意识地区分 “编” 和 “解” ，我们不能像网上有些文章一样将这两者混为一谈。

- 根据上面的解释应该可以明白，写了它之后，并不会更改本地、系统默认编码。 ~locale.getdefaultlocale~ 本地默认编码只跟操作系统相关，linux 中是 utf-8，windows 中是 gbk。
~sys.getdefaultencoding~ 系统默认编码实际是有 python3 和 python2 的差异的，python3 是 utf-8，python2 是 ascii。

- 那么，上面两种编码的作用体现在哪里呢？
系统默认编码指：在 python3 编译器读取 =.py= 文件时，若没有头文件编码声明，则默认使用“utf-8”来对 =.py= 文件进行解码。
并且在调用 =encode()= 这个函数时，不传参的话默认是“ utf-8 ”。这与下面的 =open( )= 函数中的“encoding”参数要做区分，非常误导人。

本地默认编码指：在你编写的 python3 程序时，若使用了 =open( )= 函数，而不给它传入“encoding” 这个参数，那么会自动使用本地默认编码。
没错，如果在 Windows 系统中，就是默认用 gbk 格式。
这个问题困扰了我好久， 不说好了一直默认 utf-8 到天长地久的嘛，咋换成 win 后就频频失信呢。所以请大家在这里注意：linux 中可以不用传“ encoding” 的参数， 而 win 中不能忘了。

再来回答一下报错的问题：因为我们的编译器已经用了 gbk 来解码此 =.py= 文件了，所以读取出来的变量 s 已经变成了我们现在看到的“ 灏忕敳 ” 了！
那么此时把 s 存到磁盘文件中，实际上存的是乱码后的 “ 灏忕敳 ”。而在日文中，是没有这 3 个字的，所以自然反馈说 “在 position 0 的位置，编码失败了”

现在我们再来分别查看 utf2 、gbk2、jis2 这三个文件的内容：

#+BEGIN_SRC awk
utf2 : 灏忕敳
gbk2 : 小甲
jis2 :
#+END_SRC

** 问题
- 为什么我用“utf-8 ”去编码存储，后来用 linux 默认的“ utf-8 ”去解码，却出现乱码？
- 什么我用“gbk” 去编码存储，后面用 linux 默认的“utf-8 ”去解码，明明编码、解码格式不一致，却能够正常显示？

解释：
- 实际上面两个问题是同一个问题，相信细心的同学已经知道问题出在哪里了，我上文已经说的很清楚了。
此时的变量 s 已经变成了“ 灏忕敳 ”， 那么 utf2 这个文本文件自然是显示“灏忕敳”。

而“灏忕敳”这三个字符是怎么来的呢？

#+BEGIN_SRC awk
第1步：小甲（unicode） ---用“utf-8”编码---> e5b0 8fe7 94b2 (utf-8编码后的二进制代码)
第2步：e5b0 8fe7 94b2 ---用 “gbk” 解码---> “灏忕敳”（unicode）(乱码)
第3步：“灏忕敳” --- 用“gbk”编码---> e5b0 8fe7 94b2 (第2步的逆向)
第4步：e5b0 8fe7 94b2 ---用“utf-8”解码---> 小甲（unicode）
#+END_SRC

第 3、 4 步就是逆推回去，就变成了正常的 “小甲”，看懂了这个 “编码” 和 “解码” 的过程，你的编码问题已经解决大半了。

* 三

#+BEGIN_SRC python
#coding=shift-jis
import sys, locale

s = "小甲"
print(s)
print(type(s))
print(sys.getdefaultencoding())
print(locale.getdefaultlocale(), "\n\n")

a = s.encode("shift-jis")
print(a)
print(type(a))
b = a.decode("utf-8")
print(b)
print(type(b))
print(a.decode("gbk"))

with open("utf3","w",encoding = "utf-8") as f:
    f.write(s)
with open("gbk3","w",encoding = "gbk") as f:
    f.write(s)
with open("jis3","w",encoding = "shift-jis") as f:
    f.write(s)
#+END_SRC

代码整体结构还是老样子，只不过中间多加了一小段代码，便于解释。

* 三运行结果

#+BEGIN_SRC dart
蟆冗抜
<class 'str'>
utf-8
('en_US', 'UTF-8')


b'\xe5\xb0\x8f\xe7\x94\xb2'
<class 'bytes'>
小甲
<class 'str'>
灏忕敳
#+END_SRC

这里可以看到，此时我们的变量 s 已经变成了“ 蟆冗抜 ”（另一个用 jis 解码造成的乱码）。
那么此时，我把 “蟆冗抜” 用 “shift-jis” 解码回去并赋值给变量 a，打印一下，可以看到 a 就是正常显示的 “小甲”，这也证明了我上面的推断是绝对正确的。

现在，我们依旧分别查看一下 utf3 、gbk3、jis3 这三个文件的内容：

#+BEGIN_SRC awk
utf3 : 蟆冗抜
gbk3 : ▒▒ߒi
jis3 : 小甲
#+END_SRC

这里我澄清一下，实际上 utf3 这个至少还能有文字，这叫乱码。而 gbk3 那个东西一团黑是什么鬼，是报错，linux 的默认编码无法解码 gbk3 的文件，所以打印地乱七八糟。

** 问题
- 为什么 utf3 的文件是显示乱码， 而 gbk3 的文件却是报错呢？？

** 解释
- 这是因为 utf-8 与 gbk 编码的算法差异。
- 我们最常看到的是 utf-8 解码报错，因为它是可变长的的编码，有 1 个字节的英文字符，也有 2 个字节的阿拉伯文，也有 3 个字节的中文和日文。
- gbk 对英文是使用单字节编码（也就意味着兼容 ascii），而 gbk 对中文部分是采取定长的 2 字节，总体编码范围为 8140-FEFE，首字节在 81-FE 之间，尾字节在 40-FE 之间。
  所以说它只要没有碰到尾字节在 40 之内的字符，都会一股脑地按照 2 字节去解码成中文。
  而中文在 utf-8 编码后，一般是三字节的。当解码的字节数和编码的字节数不匹配时，自然会造成全是乱码的局面。
- 而 utf-8 是有严格定义的，一个字节的字符高位必须是 0；三个字节的字符中，第一个字节的高位是 1110 开头。
- （[[https://link.zhihu.com/?target=https%3A//blog.csdn.net/hongweigg/article/details/6826836][相关utf-8的编码算法链接]]）

* 最后
- 所有文件的编码格式都由你当下使用的编辑器决定的。
  在 windows 中编辑的文本放在浏览器解析显示的时候，有时乱码，有时又正常，这是由于 windows 中很多文本编辑器默认使用和操作系统一致的编码格式。
  所以在文本存储前，一定要搞清楚我们用的是 utf-8 还是 gbk，而当你使用 Python 的 =open( )= 函数时，是内存中的进程与磁盘的交互，而这个交互过程中的编码格式则是使用操作系统的默认编码。（Linux 为 utf-8，windows 为 gbk）
- 相信学 Python 的同学们经常会听到，python3 的默认编码是 utf-8。而有的时候，又有人说 python3 的默认编码是 unicode，那么是不是会有人跟我初学时候一样傻傻分不清楚这两者的关系呢？
  实际上 unicode 就是一个字符集，一个字符与数字一一对应的映射关系，因为它一律以 2 个字节编码（或者也有 4 个字节的，这里不讨论），所以占用空间会大一些，一般只用于内存中的编码使用。
  而 utf-8 是为了实现 unicode 的传输和存储的。
  因为它可变长，存英文时候可以节省大量存储空间。
  传输时候也节省流量，所以更加 “international”。

所以说，上述两种说法没有歧义，进程在内存中的表现是“unicode”的编码；当 python3 编译器读取磁盘上的 =.py= 文件时，
是默认使用“utf-8”的；当进程中出现 =open()= , =write()= 这样的存储代码时，需要与磁盘进行存储交互时，
则是默认使用操作系统的默认编码。
