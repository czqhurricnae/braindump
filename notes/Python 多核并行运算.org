# -*- eval: (setq org-media-note-screenshot-image-dir (concat default-directory "./static/Python 多核并行运算/")); -*-
:PROPERTIES:
:ID:       0D89BE89-D49A-4211-AD88-5D3049AFF378
:END:
#+LATEX_CLASS: my-article
#+DATE: <2021-04-18 Sun 20:24>
#+TITLE: Python 多核并行运算
* GIL
CPython 中使用 GIL 使得解释器每次只执行一个线程中的字节码，除非是 IO 密集型任务，否则 CPython 的多线程没有意义。
CPython 中使用 threading 进行并行运算实际上比单线程更慢。

#+BEGIN_QUOTE
In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once.
This lock is necessary mainly because CPython’s memory management is not thread-safe.
(However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)
#+END_QUOTE

Python 为了利用多核，开始支持多线程，而解决多线程之间数据完整性和状态同步最简单的方法是加锁，于是有了 GIL 这把超级大锁。
当越来越多的代码库开发者接受这种设定后，开始大量依赖这种特性（即默认 Python 内部对象是 thread-safe 的，无需在实现时额外考虑内存锁和同步操作）。

** 顺序执行的单线程
 #+BEGIN_SRC ipython :preamble # -*- coding: utf-8 -*- :session :results output :exports no-eval
 from threading import Thread
 import time


 def my_counter():
     i = 0
     for _ in xrange(100000000):
         i = i + 1
     return True


 def main():
     start_time = time.time()
     for tid in range(2):
         t = Thread(target=my_counter)
         t.start()
         t.join()
     end_time = time.time()
     print("Total time: {}".format(end_time - start_time))


 if __name__ == "__main__":
     main()
 #+END_SRC

 #+RESULTS:
 : Total time: 7.30889415741

** 同时执行的两个并发线程
 #+BEGIN_SRC ipython :preamble # -*- coding: utf-8 -*- :session :results output :exports no-eval
   from threading import Thread
   import time


   def my_counter():
       i = 0
       for _ in xrange(100000000):
           i = i + 1
       return True


   def main():
       thread_array = {}
       start_time = time.time()
       for tid in range(2):
           t = Thread(target=my_counter)
           t.start()
           thread_array[tid] = t
       for i in range(2):
           thread_array[i].join()
       end_time = time.time()
       print("Total time: {}".format(end_time - start_time))


   if __name__ == "__main__":
       main()

 #+END_SRC

 #+RESULTS:
 : Total time: 11.5423491001

** 当前 GIL 设计的缺陷
 Python 的线程就是 C 语言的一个 pthread，并通过操作系统调度算法进行调度（Linux 中 CFS），为了让各个线程平均利用 CPU 时间，Python 计算当前已执行的微代码数量，
 达到一定阈值后强制释放 GIL，进而触发一次操作系统的线程调度（是否真正进行上下文切换由操作系统自主决定）。

 #+BEGIN_SRC python
   while True:
       acquire GIL
       for i in 1000:
           do something
       release GIL:
       # Give operating system a chance to do  threading shceduling.
 #+END_SRC

 这种模式在只有一个 CPU 核心的情况下毫无问题，任何一个线程被唤起都能成功或得到 GIL（因为只有释放了 GIL 才会引发线程调度）。
 但当 CPU 有多个核心是， “release GIL“ 到“acquire GIL“ 之间几乎没有间隙，所以当其他核心上的线程被唤醒是，大部分情况下主线程已经又再一次获取到 GIL，
 而被唤醒执行的线程只能白白浪费 CPU 时间，看着另一个线程拿个 GIL 欢快执行。
 然后达到切换时间后进入待调度状态，再被唤醒，再等待，以此往复恶性循环。

 Python 的每个版本在都在逐渐改进 GIL 和线程调度之间的互动关系，例如先持有 GIL 再做线程上下文切换，在 IO 等待时间释放 GIL 等。
 但是无法改变的是 GIL 的存在使得操作系统线程调度的这个本来就昂贵的操作变得更奢侈了。
 两个线程均为 CPU 密集型，绿色表示该线程运行，且在执行有用的计算，
 红色表示线程被调度唤醒，但是无法获取 GIL 导致无法进行有效运算等待的时间。

 #+CAPTION: 两个线程在双核 CPU 上的执行情况
 [[file:./static/Python 多核并行运算/2021-04-18_20-35-51.png]]


 可见 GIL 导致多线程无法很好的利用多核 CPU 的并发处理能力.

 #+CAPTION: 一个 CPU 密集型线程对 IO 密集型线程的影响
 [[file:./static/Python 多核并行运算/2021-04-18_20-37-55.png]]


 当 IO 线程收到数据包引起终端切换后，仍然由于一个 CPU 密集型线程的存在，导致无法获取 GIL 锁，进而进行无尽的循环等待。

 总结：Python 的多线程在多核 CPU 上， 只对 IO 密集型计算有正面效果，当至少有一个 CPU 密集型计算线程存在，那么多线程效率就会由于 GIL 而大幅下降。

** Reworking the GIL
 - 将切换颗粒度从基于 opcode 计数改成基于时间片计数。
 - 避免最近一次释放 GIL 锁的线程再次被立即调度。
 - 新增线程优先级功能(高优先级线程可以迫使其他线程释放所持有的 GIL 锁)。

** Multiprocessing.Pool
 #+BEGIN_SRC ipython :preamble # -*- coding: utf-8 -*- :session :results output :exports no-eval
 # -*- coding:utf-8 -*-
 import multiprocessing
 import sys

 def f(x):
     return x * x


 cores = multiprocessing.cpu_count()
 pool = multiprocessing.Pool(processes=cores)
 xs = range(5)


 # Method 1: map
 print pool.map(func=f, iterable=xs)


 # Method 2: imap
 for y in pool.imap(func=f, iterable=xs):
     print y


 # Method 3: imap_unordered
 cnt = 0
 for _ in pool.imap_unordered(func=f, iterable=xs):
     sys.stdout.write("done %d/%d\r" % (cnt, len(xs)))
     cnt += 1
 #+END_SRC

 #+RESULTS:
 : [0, 1, 4, 9, 16]
 : 0
 : 1
 : 4
 : 9
 : 16
 : done 0/5done 1/5done 2/5done 3/5done 4/5

 # 使用 Theano 或者 Tensorflow 等工具时的注意事项
 需要注意的是， 在 import theano 或者 import tensorflow 等调用了 Cuda 的工具的时候会产生一些副作用， 这些副作用会原样拷贝到子进程中， 然后就发生错误， 如：
 解决的方法是， 保证父进程不引入这些工具， 而是在子进程创建好后， 让子进程各自引入。

** 如果使用 Process, 那就在 target 函数里面 import
 #+BEGIN_SRC python
 import multiprocessing


 def hello(taskq, resultq):
     import tensorflow as tf
     config = tf.ConfigProto()
     config.gpu_options.allow_growth = True
     sess = tf.Session(config=config)
     while True:
         name = taskq.get()
         res = sess.run(tf.constant('hello ' + name))
         resultq.put(res)


 if __name__ == '__main__':
     taskq = multiprocessing.Queue()
     resultq = multiprocessing.Queue()
     p = multiprocessing.Process(target=hello, args=(taskq, resultq))
     p.start()

     taskq.put('world')
     taskq.put('abcdabcd987')
     taskq.close()

     print(resultq.get())

     print(resultq.get())

     p.terminate()
     p.join()
 #+END_SRC

 #+BEGIN_SRC python
   could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED
 #+END_SRC

* 如果使用 Pool, 那么可以编写一个函数, 在这个函数里面 import, 并且把这个函数作为 initializer 传入到 Pool 的构造函数里面
 #+BEGIN_SRC python
 import multiprocessing


 def init():
     global tf
     global sess
     import tensorflow as tf
     config = tf.ConfigProto()
     config.gpu_options.allow_growth = True
     sess = tf.Session(config=config)


 def hello(name):
     return sess.run(tf.constant('hello ' + name))


 if __name__ == '__main__':
     pool = multiprocessing.Pool(processes=2, initializer=init)
     xs = ['world', 'abcdabcd987', 'Lequn Chen']
     print pool.map(hello, xs)
 #+END_SRC

* Backlinks                                                        :noexport:
** No linked reference

** Unlinked references
[Show unlinked references]
